{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n======================================================================================\n12. Computing utilities\n======================================================================================\n\n**Suhas Somnath**\n\n8/12/2017\n\n**This is a short walk-through of useful utilities in pyUSID.processing.comp_utils that simplify common computational\ntasks.**\n\n.. tip::\n    You can download and run this document as a Jupyter notebook using the link at the bottom of this page.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function, division, unicode_literals\nfrom multiprocessing import cpu_count\nimport subprocess\nimport sys\n\n\ndef install(package):\n    subprocess.call([sys.executable, \"-m\", \"pip\", \"install\", package])\n# Package for downloading online files:\ntry:\n    import pyUSID as usid\nexcept ImportError:\n    print('pyUSID not found.  Will install with pip.')\n    import pip\n    install('pyUSID')\n    import pyUSID as usid"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "parallel_compute()\n------------------\nOften, we are encountered with a task that needs to be repeated *independently* over N pieces of data, such as fitting\nN curves to a polynomial function. Using a for-loop to process each of the N curves sequentially can be slow and will\nnot use the available computational power of the CPU. Given that the processing of one curve will not affect that of\nanother curve, this operation can be performed in parallel much faster using the multiple CPU cores that are available\nin typical modern CPUs. The ``parallel_compute()`` function simplifies the process of distributing such an inherently\nparallel operation over multiple CPU cores in a *single CPU*.\nPlease see `this separate document <./plot_parallel_compute.html>`_ for a detailed tutorial\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "recommend_cpu_cores()\n---------------------\nTime is of the essence and every developer wants to make the best use of all available cores in a CPU for massively\nparallel computations. ``recommend_cpu_cores()`` is a popular function that looks at the number of parallel operations,\navailable CPU cores, duration of each computation to recommend the number of cores that should be used for any\ncomputation. If the developer / user requests the use of N CPU cores, this function will validate this number against\nthe number of available cores and the nature (lengthy / quick) of each computation. Unless, a suggested number of\ncores is specified, ``recommend_cpu_cores()`` will always recommend the usage of N-2 CPU cores, where N is the total\nnumber of logical cores (Intel uses hyper-threading) on the CPU to avoid using up all computational resources and\npreventing the computation from making the computer otherwise unusable until the computation is complete\nHere, we demonstrate this function being used in a few use cases:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print('This CPU has {} cores available'.format(cpu_count()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Case 1**: several independent computations or jobs, each taking far less than 1 second. The number of desired cores\nis not specified. The function will return 2 lesser than the total number of cores on the CPU\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "num_jobs = 14035\nrecommeded_cores = usid.processing.comp_utils.recommend_cpu_cores(num_jobs, lengthy_computation=False)\nprint('Recommended number of CPU cores for {} independent, FAST, and parallel '\n      'computations is {}\\n'.format(num_jobs, recommeded_cores))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Case 2**: Several independent and fast computations, and the function is asked if 3 cores is OK. In this case, the\nfunction will allow the usage of the 3 cores so long as the CPU actually has 3 or more cores\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "requested_cores = 3\nrecommeded_cores = usid.processing.comp_utils.recommend_cpu_cores(num_jobs, requested_cores=requested_cores, lengthy_computation=False)\nprint('Recommended number of CPU cores for {} independent, FAST, and parallel '\n      'computations using the requested {} CPU cores is {}\\n'.format(num_jobs, requested_cores, recommeded_cores))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Case 3**: Far fewer independent and fast computations, and the function is asked if 3 cores is OK. In this case,\nconfiguring multiple cores for parallel computations will probably be slower than serial computation with a single\ncore. Hence, the function will recommend the use of only one core in this case.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "num_jobs = 13\nrecommeded_cores = usid.processing.comp_utils.recommend_cpu_cores(num_jobs, requested_cores=requested_cores, lengthy_computation=False)\nprint('Recommended number of CPU cores for {} independent, FAST, and parallel '\n      'computations using the requested {} CPU cores is {}\\n'.format(num_jobs, requested_cores, recommeded_cores))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Case 4**: The same number of a few independent computations but each of these computations are expected to be\nlengthy. In this case, the overhead of configuring the CPU core for parallel computing is worth the benefit of\nparallel computation. Hence, the function will allow the use of the 3 cores even though the number of computations is\nsmall.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "recommeded_cores = usid.processing.comp_utils.recommend_cpu_cores(num_jobs, requested_cores=requested_cores, lengthy_computation=True)\nprint('Recommended number of CPU cores for {} independent, SLOW, and parallel '\n      'computations using the requested {} CPU cores is {}'.format(num_jobs, requested_cores, recommeded_cores))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "get_available_memory()\n----------------------\nAmong the many best-practices we follow when developing a new data analysis or processing class is memory-safe\ncomputation. This handy function helps us quickly get the available memory. Note that this function returns the\navailable memory in bytes. So, we have converted it to gigabytes here:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print('Available memory in this machine: {} GB'.format(usid.processing.comp_utils.get_available_memory() / 1024 ** 3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The following functions are harder to demonstrate in this document since they are meant for a cluster of computers\nrather than a conventional personal computer.\n\nget_MPI()\n---------\nThis function is useful for getting a handle to the Message Passing Interface (MPI) communicator if one is available.\nIf the ``mpi4py`` package is not installed or if ``mpi4py`` is being run over a single CPU, this function returns\n``None`` instead. Given that this documentation was generated by a single small virtual machine without the invoking\n``mpirun`` or ``mpixec``, the following call to ``get_MPI()`` should return ``None``\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(usid.processing.comp_utils.get_MPI())\n\n# group_ranks_by_socket()\n# -----------------------\n# As the name suggests, this function assigns a master rank for each rank such that there is a single master rank per\n# socket (CPU). The results from this function can be used to split MPI communicators based on the socket for\n# intra-node communication."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}